{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "#Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "#Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "#Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "jrOQbp9ctBBB",
        "outputId": "5ce38a98-2ced-4e04-ccff-753c3ae22fe2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,284 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,498 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,520 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,016 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,244 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,242 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,152 kB]\n",
            "Fetched 10.2 MB in 3s (3,510 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "32 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=96a3154c216efac33a1b794b7cf4be112b337437ce62c0eb94b0eb60406daea2\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.5.0-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjHB4KDDtD0u",
        "outputId": "4b977c42-22e3-4b9c-ce91-f9dc5d8606e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when, col\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "wZG0XeHotb7X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Crear una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"ReviewSentimentAnalyzer\").getOrCreate()"
      ],
      "metadata": {
        "id": "hmQfULQatd_0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Cargar el conjunto de datos (reemplaza 'tu_archivo.csv' con la ruta real)\n",
        "data = spark.read.csv('/content/drive/My Drive/Colab Notebooks/Books_rating.csv', header=True, inferSchema=True)\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6eCQdbmthF8",
        "outputId": "bb589bce-fc4d-4fc0-ffaa-dc89ba1e61c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|1882931173|Its Only Art If I...| NULL| AVCGYZL8FQQTD|\"Jim of Oz \"\"jim-...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A30TK6U7DNS82R|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A3UH4UZ4RSVO82|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|\"If people become...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A2MVUWT453QH61|\"Roy E. Perry \"\"a...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A22X4XUPKF66MR|\"D. H. Richards \"...|               3/3|         4.0| 1107993600|Good academic ove...|\"Philip Nel - Dr....|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A2F6NONFUDB6UK|              Malvin|               2/2|         4.0| 1127174400|One of America's ...|\"\"\"Dr. Seuss: Ame...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A14OJS0VWMOSWO| Midwest Book Review|               3/4|         5.0| 1100131200|A memorably excel...|Theodor Seuss Gie...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A2RSSXTDZDUSH4|           J. Squire|               0/0|         5.0| 1231200000|Academia At It's ...|\"When I recieved ...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A25MD5I2GUIW6W|\"J. P. HIGBED \"\"b...|               0/0|         5.0| 1209859200|And to think that...|\"Trams (or any pu...|\n",
            "|0826414346|Dr. Seuss: Americ...| NULL|A3VA4XFS5WNJO3|     Donald Burnside|               3/5|         4.0| 1076371200|Fascinating accou...|As far as I am aw...|\n",
            "|0829814000|Wonderful Worship...|19.40| AZ0IOBU20TBOP|  Rev. Pamela Tinnin|              8/10|         5.0|  991440000|Outstanding Resou...|I just finished t...|\n",
            "|0829814000|Wonderful Worship...|19.40|A373VVEU6Z9M0N|Dr. Terry W. Dorsett|               1/1|         5.0| 1291766400|Small Churches CA...|\"Many small churc...|\n",
            "|0829814000|Wonderful Worship...|19.40| AGKGOH65VTRR4|\"Cynthia L. Lajoy...|               1/1|         5.0| 1248307200|Not Just for Past...|I just finished r...|\n",
            "|0829814000|Wonderful Worship...|19.40| A3OQWLU31BU1Y|       Maxwell Grant|               1/1|         5.0| 1222560000|Small church past...|\"I hadn't been a ...|\n",
            "|0595344550|Whispers of the W...|10.95|A3Q12RK71N74LB|         Book Reader|              7/11|         1.0| 1117065600|            not good|I bought this boo...|\n",
            "|0595344550|Whispers of the W...|10.95|A1E9M6APK30ZAU|           V. Powell|               1/2|         4.0| 1119571200|  Here is my opinion|\"I have to admit,...|\n",
            "|0595344550|Whispers of the W...|10.95| AUR0VA5H0C66C|\"LoveToRead \"\"Act...|               1/2|         1.0| 1119225600|        Buyer beware|\"This is a self-p...|\n",
            "|0595344550|Whispers of the W...|10.95|A1YLDZ3VHR6QPZ|               Clara|               2/4|         5.0| 1115942400| Fall on your knee's|When I first read...|\n",
            "|0595344550|Whispers of the W...|10.95| ACO23CG8K8T77|               Tonya|               5/9|         5.0| 1117065600|      Bravo Veronica|I read the review...|\n",
            "|0595344550|Whispers of the W...|10.95|A1VK81CRRC7MLM|\"missyLou \"\"apple\"\"\"|               1/3|         5.0| 1130025600|           Wonderful|\"I really enjoyed...|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Count null values in each column\n",
        "null_counts = [data.where(col(c).isNull()).count() for c in data.columns]\n",
        "\n",
        "# Step 4: Display the results\n",
        "for column, null_count in zip(data.columns, null_counts):\n",
        "    print(f\"Column '{column}': {null_count} null values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC_r9dnOx2eK",
        "outputId": "1704e0ea-9c32-4b87-f5c6-27effb721a8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Id': 0 null values\n",
            "Column 'Title': 208 null values\n",
            "Column 'Price': 2517579 null values\n",
            "Column 'User_id': 562250 null values\n",
            "Column 'profileName': 562200 null values\n",
            "Column 'review/helpfulness': 367 null values\n",
            "Column 'review/score': 130 null values\n",
            "Column 'review/time': 27 null values\n",
            "Column 'review/summary': 65 null values\n",
            "Column 'review/text': 43 null values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se agrega una columna 'sentiment' basada en la 'review/score'\n",
        "# donde se asigna 1 si 'review/score' es mayor a 3.0, y 0 en caso contrario\n",
        "data = data.withColumn(\"sentiment\", when(col(\"review/score\") > 3.0, 1).otherwise(0))"
      ],
      "metadata": {
        "id": "SxHcUxbe5OpC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina filas con valores nulos\n",
        "data = data.select(\"review/text\", \"sentiment\").na.drop()"
      ],
      "metadata": {
        "id": "d-FKE8Bq2f7h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de Datos"
      ],
      "metadata": {
        "id": "e-zFnkTLNwVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza Tokenizer para dividir el texto en palabras\n",
        "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
        "# Se utiliza StopWordsRemover para eliminar palabras comunes.\n",
        "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "# Se utiliza HashingTF para convertir las palabras en características numéricas.\n",
        "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
        "# Se utiliza IDF para ajustar los pesos de las características, con una frecuencia mínima de documento de 5.\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=5)"
      ],
      "metadata": {
        "id": "0Xljqo0n1ojJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "h7Xb57CxOSpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza LogisticaRegression\n",
        "# 'featuresCol' se configura con las características preprocesadas y 'labelCol' con la columna 'sentiment'\n",
        "# Se establece el número máximo de iteraciones en 10 y el parámetro de regularización en 0.01\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"sentiment\", maxIter=10, regParam=0.01)"
      ],
      "metadata": {
        "id": "xgS79uGD1sEW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea un Pipeline que encadena las etapas de preprocesamiento y entrenamiento del modelo\n",
        "pipeline = Pipeline(stages=[tokenizer, stop_words_remover, hashing_tf, idf, lr])"
      ],
      "metadata": {
        "id": "MeZzEcwQ1xHM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se dividen los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
        "(training_data, test_data) = data.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "RWRC8N4M1zHf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se entrena el modelo utilizando los datos de entrenamiento\n",
        "model = pipeline.fit(training_data)"
      ],
      "metadata": {
        "id": "s4YX56kN11BP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluar el modelo"
      ],
      "metadata": {
        "id": "wOsi6bTePL95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realizan predicciones utilizando el modelo entrenado en el conjunto de prueba.\n",
        "predictions = model.transform(test_data)"
      ],
      "metadata": {
        "id": "wjlKmNyd18v6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza BinaryClassificationEvaluator para evaluar la precisión del modelo en el conjunto de prueba\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"sentiment\")\n",
        "# Se calcula la precisión del modelo.\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5KYS6kT19WV",
        "outputId": "5301cc61-ce4e-4802-97d6-c6134825bee9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8925118254093743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hacer predicciones con un Input del usuario"
      ],
      "metadata": {
        "id": "fTY5QVTJQjWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pedir un review al usuario\n",
        "user_review = input(\"Enter your review: \")\n",
        "\n",
        "# Meter el input del usuario en un spark dataframe\n",
        "user_data = spark.createDataFrame([(user_review,)], [\"review/text\"])\n",
        "\n",
        "# Hacer la prediccion\n",
        "prediction = model.transform(user_data)\n",
        "\n",
        "# Extraer la prediccion del sentimiento\n",
        "predicted_sentiment = prediction.select(\"prediction\").collect()[0][0]\n",
        "\n",
        "# Mostrar la predicccion de sentimiento\n",
        "if predicted_sentiment == 1.0:\n",
        "    print(\"Sentiment: Positive\")\n",
        "else:\n",
        "    print(\"Sentiment: Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LWE6MY1AcFc",
        "outputId": "c313cd1b-253a-425a-e157-0c9f9aba1f2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your review: I like this book, it is very fun!\n",
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/BookReview_Sentiment_Analysis\")"
      ],
      "metadata": {
        "id": "7j6DSCC_AyT_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hacer prediccion con el Modelo Guardado\n",
        "Ya no hay necesidad de entrenar desde 0"
      ],
      "metadata": {
        "id": "EVvqm-3XSl_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.sql.functions import when, col"
      ],
      "metadata": {
        "id": "-b-B2QGeSXLp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/Colab Notebooks/BookReview_Sentiment_Analysis\"\n",
        "loaded_model = PipelineModel.load(saved_model_path)\n",
        "\n",
        "user_review = input(\"Ingrese su revisión: \")\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
        "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=5)\n",
        "\n",
        "user_data = spark.createDataFrame([(user_review,)], [\"review/text\"])\n",
        "\n",
        "# Hacer la prediccion\n",
        "prediction = loaded_model.transform(user_data)\n",
        "\n",
        "# Extraer la prediccion del sentimiento\n",
        "predicted_sentiment = prediction.select(\"prediction\").collect()[0][0]\n",
        "\n",
        "# Mostrar la predicccion de sentimiento\n",
        "if predicted_sentiment == 1.0:\n",
        "    print(\"Sentiment: Positive\")\n",
        "else:\n",
        "    print(\"Sentiment: Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G2W6hT9Rhl3",
        "outputId": "7df75bc6-23ef-40da-9f33-263aae1f62a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingrese su revisión: This book sucks, its terrible. I want to give it back.\n",
            "Sentiment: Negative\n"
          ]
        }
      ]
    }
  ]
}